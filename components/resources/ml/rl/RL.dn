uses data.String

/*
{"description" : "A reinforcement learning algorithm. To begin with, setActions must be used to provide a uniquely-identified set of possible actions. Following this, getAction and setReward are called continuously, in a loop, to drive the learning algorithm. The index returned by getAction is an index into the list of actions supplied to setActions, after which the calling entity waits for some amount of time before calling setReward with the reward level observed from the system."}
*/

interface RL {
	
	/* { "@description" : "Set the exploration penalty of the algorithm, to balance the tradeoff of explore/exploit. The default is 1.0, indicating no penalty, with higher values increasing the penalty."} */
	void setExplorationPenalty(dec penalty)
	
	/* { "@description" : "Set the list of available actions."} */
	void setActions(store String actions[])
	
	/* { "@description" : "Get the next action index requested by the learning algorithm."} */
	int getAction()
	
	/* { "@description" : "Set the reward gained for taking a given action. If no action parameter is provided, the algorithm assumes that this reward relates to the last action returned by getAction()."} */
	void setReward(dec reward, opt int action)
	
	/* { "@description" : "Get the most highly-rewarded n actions."} */
	int[] getTopActions(int n)
	
	}